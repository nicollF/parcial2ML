{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Punto 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelos de clasificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mglearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabels = pd.read_csv(r'C:\\Users\\Usuario\\Downloads\\train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeddata = pd.read_csv(r'C:\\Users\\Usuario\\Pictures\\SegundoParcial_ML\\encoded_traindata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>R_1</th>\n",
       "      <th>D_41</th>\n",
       "      <th>D_43</th>\n",
       "      <th>B_5</th>\n",
       "      <th>D_46</th>\n",
       "      <th>B_6</th>\n",
       "      <th>...</th>\n",
       "      <th>D_117_2.319056498594235</th>\n",
       "      <th>D_117_3.0</th>\n",
       "      <th>D_117_4.0</th>\n",
       "      <th>D_117_5.0</th>\n",
       "      <th>D_117_6.0</th>\n",
       "      <th>D_120_0.0</th>\n",
       "      <th>D_120_1.0</th>\n",
       "      <th>D_126_-1.0</th>\n",
       "      <th>D_126_0.0</th>\n",
       "      <th>D_126_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.170600</td>\n",
       "      <td>0.358587</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.113239</td>\n",
       "      <td>0.353630</td>\n",
       "      <td>0.065261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.060492</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.066982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.166782</td>\n",
       "      <td>0.323271</td>\n",
       "      <td>0.083720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.231009</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        customer_ID         S_2  \\\n",
       "0      0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09   \n",
       "1      1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07   \n",
       "2      2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28   \n",
       "3      3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13   \n",
       "4      4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16   \n",
       "\n",
       "       D_39       R_1      D_41      D_43       B_5      D_46       B_6  ...  \\\n",
       "0  0.001733  0.009228  0.008771  0.088512  0.170600  0.358587  0.063902  ...   \n",
       "1  0.005775  0.006151  0.000798  0.088512  0.113239  0.353630  0.065261  ...   \n",
       "2  0.091505  0.006815  0.007598  0.088512  0.060492  0.334650  0.066982  ...   \n",
       "3  0.002455  0.001373  0.000685  0.088512  0.166782  0.323271  0.083720  ...   \n",
       "4  0.002483  0.007605  0.004653  0.088512  0.143630  0.231009  0.075900  ...   \n",
       "\n",
       "   D_117_2.319056498594235  D_117_3.0  D_117_4.0  D_117_5.0  D_117_6.0  \\\n",
       "0                      0.0        0.0        1.0        0.0        0.0   \n",
       "1                      0.0        0.0        1.0        0.0        0.0   \n",
       "2                      0.0        0.0        1.0        0.0        0.0   \n",
       "3                      0.0        0.0        1.0        0.0        0.0   \n",
       "4                      0.0        0.0        1.0        0.0        0.0   \n",
       "\n",
       "   D_120_0.0  D_120_1.0  D_126_-1.0  D_126_0.0  D_126_1.0  \n",
       "0        1.0        0.0         0.0        0.0        1.0  \n",
       "1        1.0        0.0         0.0        0.0        1.0  \n",
       "2        1.0        0.0         0.0        0.0        1.0  \n",
       "3        1.0        0.0         0.0        0.0        1.0  \n",
       "4        1.0        0.0         0.0        0.0        1.0  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodeddata = encodeddata.drop(columns=['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encodeddata.drop(columns=['customer_ID'])\n",
    "y = trainlabels['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = y.shape[0]\n",
    "indices = np.random.choice(X.index, size=num_samples, replace=False)\n",
    "X_sampled = X.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "458908    0\n",
       "458909    0\n",
       "458910    0\n",
       "458911    1\n",
       "458912    0\n",
       "Name: target, Length: 458913, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    340085\n",
       "1    118828\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>D_39</th>\n",
       "      <th>R_1</th>\n",
       "      <th>D_41</th>\n",
       "      <th>D_43</th>\n",
       "      <th>B_5</th>\n",
       "      <th>D_46</th>\n",
       "      <th>B_6</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>...</th>\n",
       "      <th>D_117_2.319056498594235</th>\n",
       "      <th>D_117_3.0</th>\n",
       "      <th>D_117_4.0</th>\n",
       "      <th>D_117_5.0</th>\n",
       "      <th>D_117_6.0</th>\n",
       "      <th>D_120_0.0</th>\n",
       "      <th>D_120_1.0</th>\n",
       "      <th>D_126_-1.0</th>\n",
       "      <th>D_126_0.0</th>\n",
       "      <th>D_126_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2906809</th>\n",
       "      <td>2906809</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.009801</td>\n",
       "      <td>0.538259</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.674791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898658</th>\n",
       "      <td>3898658</td>\n",
       "      <td>0.682484</td>\n",
       "      <td>0.754367</td>\n",
       "      <td>1.583614</td>\n",
       "      <td>0.138661</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>0.563258</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711636</th>\n",
       "      <td>711636</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.451559</td>\n",
       "      <td>0.085667</td>\n",
       "      <td>0.341024</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084467</th>\n",
       "      <td>2084467</td>\n",
       "      <td>0.538912</td>\n",
       "      <td>0.504558</td>\n",
       "      <td>0.004699</td>\n",
       "      <td>0.070885</td>\n",
       "      <td>0.020854</td>\n",
       "      <td>0.466994</td>\n",
       "      <td>0.042019</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.625897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487693</th>\n",
       "      <td>4487693</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.136021</td>\n",
       "      <td>0.459670</td>\n",
       "      <td>0.058275</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.048818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480601</th>\n",
       "      <td>2480601</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.088512</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.467809</td>\n",
       "      <td>0.244064</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129684</th>\n",
       "      <td>129684</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.459670</td>\n",
       "      <td>0.259649</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093142</th>\n",
       "      <td>2093142</td>\n",
       "      <td>0.302166</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.147523</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.697685</td>\n",
       "      <td>0.345436</td>\n",
       "      <td>1.340518</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999765</th>\n",
       "      <td>999765</td>\n",
       "      <td>0.621731</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.045740</td>\n",
       "      <td>0.268905</td>\n",
       "      <td>0.447492</td>\n",
       "      <td>0.199264</td>\n",
       "      <td>0.674312</td>\n",
       "      <td>0.024728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898309</th>\n",
       "      <td>4898309</td>\n",
       "      <td>0.361083</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.654859</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.024546</td>\n",
       "      <td>0.460538</td>\n",
       "      <td>0.011538</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.512710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index      D_39       R_1      D_41      D_43       B_5      D_46  \\\n",
       "2906809  2906809  0.031813  0.003997  0.008409  0.088512  0.009801  0.538259   \n",
       "3898658  3898658  0.682484  0.754367  1.583614  0.138661  0.018284  0.563258   \n",
       "711636    711636  0.003105  0.008810  0.004198  0.088512  0.004675  0.451559   \n",
       "2084467  2084467  0.538912  0.504558  0.004699  0.070885  0.020854  0.466994   \n",
       "4487693  4487693  0.009726  0.001643  0.006045  0.088512  0.136021  0.459670   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "2480601  2480601  0.006673  0.004518  0.008016  0.088512  0.000173  0.467809   \n",
       "129684    129684  0.000337  0.004435  0.002930  0.014795  0.006076  0.459670   \n",
       "2093142  2093142  0.302166  0.008770  0.002372  0.147523  0.002633  0.697685   \n",
       "999765    999765  0.621731  0.009951  0.005859  0.045740  0.268905  0.447492   \n",
       "4898309  4898309  0.361083  0.006872  0.654859  0.098566  0.024546  0.460538   \n",
       "\n",
       "              B_6      D_51       B_9  ...  D_117_2.319056498594235  \\\n",
       "2906809  0.003314  0.002636  0.674791  ...                      0.0   \n",
       "3898658  0.018062  0.001740  0.001101  ...                      0.0   \n",
       "711636   0.085667  0.341024  0.004294  ...                      0.0   \n",
       "2084467  0.042019  0.009809  0.625897  ...                      0.0   \n",
       "4487693  0.058275  0.004760  0.048818  ...                      0.0   \n",
       "...           ...       ...       ...  ...                      ...   \n",
       "2480601  0.244064  0.009888  0.007605  ...                      0.0   \n",
       "129684   0.259649  0.009999  0.003013  ...                      0.0   \n",
       "2093142  0.345436  1.340518  0.007119  ...                      0.0   \n",
       "999765   0.199264  0.674312  0.024728  ...                      0.0   \n",
       "4898309  0.011538  0.007146  0.512710  ...                      0.0   \n",
       "\n",
       "         D_117_3.0  D_117_4.0  D_117_5.0  D_117_6.0  D_120_0.0  D_120_1.0  \\\n",
       "2906809        0.0        1.0        0.0        0.0        0.0        1.0   \n",
       "3898658        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "711636         1.0        0.0        0.0        0.0        1.0        0.0   \n",
       "2084467        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "4487693        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "2480601        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "129684         0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "2093142        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "999765         0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "4898309        0.0        0.0        0.0        1.0        1.0        0.0   \n",
       "\n",
       "         D_126_-1.0  D_126_0.0  D_126_1.0  \n",
       "2906809         0.0        0.0        1.0  \n",
       "3898658         0.0        0.0        1.0  \n",
       "711636          0.0        0.0        1.0  \n",
       "2084467         0.0        0.0        1.0  \n",
       "4487693         0.0        0.0        1.0  \n",
       "...             ...        ...        ...  \n",
       "2480601         0.0        0.0        1.0  \n",
       "129684          0.0        0.0        1.0  \n",
       "2093142         0.0        0.0        1.0  \n",
       "999765          1.0        0.0        0.0  \n",
       "4898309         0.0        1.0        0.0  \n",
       "\n",
       "[458913 rows x 117 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en train y test\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_sampled, y, stratify=y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # **Modelos sin ADDSYN** -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio, se utilizaron las métricas accuracy y precision, ya que eran las más apropiadas para entrenar y evaluar los modelos en este contexto. La exactitud fue relevante porque proporciona una visión general del rendimiento, midiendo el porcentaje de predicciones correctas. Sin embargo, debido al desbalanceo de clases presente, también se consideró la precision, que es fundamental para evitar un exceso de falsos positivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos sin ADDASYN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **k-nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:  {'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "Mejor score de entrenamiento:  0.2643652990388041\n",
      "Precisión en el conjunto de test:  0.24343714332300667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = [{\n",
    "    'knn__n_neighbors': range(3, 15),\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}]\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "# Usando precisión como métrica de scoring\n",
    "grid_search_k = GridSearchCV(pipeline, param_grid, cv=k_fold, scoring='precision', n_jobs=-1)\n",
    "\n",
    "grid_search_k.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_parameters = grid_search_k.best_params_\n",
    "best_score = grid_search_k.best_score_\n",
    "\n",
    "# Predicciones en el conjunto de test\n",
    "model_pred_knn = grid_search_k.predict(X_test)\n",
    "\n",
    "# Calcular la precisión en el conjunto de test\n",
    "precision_test = precision_score(y_test, model_pred_knn)\n",
    "\n",
    "print(\"Mejores parámetros: \", best_parameters)\n",
    "print(\"Mejor score de entrenamiento: \", best_score)\n",
    "print('Precisión en el conjunto de test: ', precision_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_test, model_pred_knn)\n",
    "recall_test = recall_score(y_test, model_pred_knn)\n",
    "f1_test = f1_score(y_test, model_pred_knn)\n",
    "probabilities_knn = grid_search_k.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test, probabilities_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de test:  0.24343714332300667\n",
      "Recall en el conjunto de test:  0.04206937360872383\n",
      "F1-score en el conjunto de test:  0.0717409062515016\n",
      "AUC en el conjunto de test:  0.49948296188315183\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión en el conjunto de test: \", precision_test)\n",
    "print(\"Recall en el conjunto de test: \", recall_test)\n",
    "print(\"F1-score en el conjunto de test: \", f1_test)\n",
    "print(\"AUC en el conjunto de test: \", auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regresión logistica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:  {'logreg__C': 100}\n",
      "Mejor score de entrenamiento:  0.502884498285086\n",
      "Score en el conjunto de test:  0.5014358515582154\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "param_grid = [{\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100] \n",
    "}]\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "grid_search_lr = GridSearchCV(pipeline, param_grid, cv=k_fold, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "grid_search_lr.fit(X_trainval, y_trainval)\n",
    "\n",
    "best_parameters = grid_search_lr.best_params_\n",
    "best_score = grid_search_lr.best_score_\n",
    "\n",
    "model_pred_lr = grid_search_lr.predict(X_test)\n",
    "prob_lr = grid_search_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Mejores parámetros: \", best_parameters)\n",
    "print(\"Mejor score de entrenamiento: \", best_score)\n",
    "print('Score en el conjunto de test: ',roc_auc_score(y_test, prob_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score en el conjunto de entrenamiento: 0.7411\n",
      "Score en el conjunto de prueba: 0.7422\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_predl1ad = model.predict(X_test)\n",
    "\n",
    "# Obtener el score (precisión) en los conjuntos de entrenamiento y prueba\n",
    "train_score = model.score(X_trainval, y_trainval)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "# Imprimir los scores\n",
    "print(f'Score en el conjunto de entrenamiento: {train_score:.4f}')\n",
    "print(f'Score en el conjunto de prueba: {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = precision_score(y_test, y_predl1ad)\n",
    "recall_test = recall_score(y_test, y_predl1ad)\n",
    "f1_test = f1_score(y_test, y_predl1ad)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.2434\n",
      "Recall en el conjunto de prueba: 0.0421\n",
      "F1-score en el conjunto de prueba: 0.0717\n",
      "AUC en el conjunto de prueba: 0.4995\n"
     ]
    }
   ],
   "source": [
    "print(f'Precisión en el conjunto de prueba: {precision_test:.4f}')\n",
    "print(f'Recall en el conjunto de prueba: {recall_test:.4f}')\n",
    "print(f'F1-score en el conjunto de prueba: {f1_test:.4f}')\n",
    "print(f'AUC en el conjunto de prueba: {auc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score en el conjunto de entrenamiento: 0.7411\n",
      "score en el conjunto de prueba: 0.7422\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "model.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "y_pred_train = model.predict(X_trainval)\n",
    "y_pred_testl2 = model.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar el score para el conjunto de entrenamiento\n",
    "train_score = accuracy_score(y_trainval, y_pred_train)\n",
    "print(f'score en el conjunto de entrenamiento: {train_score:.4f}')\n",
    "\n",
    "# Calcular y mostrar el score para el conjunto de prueba\n",
    "test_score = accuracy_score(y_test, y_pred_testl2)\n",
    "print(f'score en el conjunto de prueba: {test_score:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.0000\n",
      "Recall en el conjunto de prueba: 0.0000\n",
      "F1-score en el conjunto de prueba: 0.0000\n",
      "AUC en el conjunto de prueba: 0.4984\n"
     ]
    }
   ],
   "source": [
    "precision_test = precision_score(y_test, y_pred_testl2)\n",
    "recall_test = recall_score(y_test, y_pred_testl2)\n",
    "f1_test = f1_score(y_test, y_pred_testl2)\n",
    "y_pred_probal2 = model.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test, y_pred_probal2)\n",
    "print(f'Precisión en el conjunto de prueba: {precision_test:.4f}')\n",
    "print(f'Recall en el conjunto de prueba: {recall_test:.4f}')\n",
    "print(f'F1-score en el conjunto de prueba: {f1_test:.4f}')\n",
    "print(f'AUC en el conjunto de prueba: {auc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificador Bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422243851417116"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_trainval, y_trainval)\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_sc, y_trainval)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7422\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "AUC: 0.5010\n"
     ]
    }
   ],
   "source": [
    "y_prob = clf.predict_proba(X_test_sc)[:, 1]  # Probabilidades para la clase positiva\n",
    "\n",
    "# Calcular métricas clásicas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelos con ADDSYN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **k-nn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:  {'knn__n_neighbors': 13, 'knn__weights': 'distance'}\n",
      "Mejor score de entrenamiento:  0.2643652990388041\n",
      "Precisión en el conjunto de test:  0.24343714332300667\n"
     ]
    }
   ],
   "source": [
    "# Configuración del pipeline de KNN\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = [{\n",
    "    'knn__n_neighbors': range(3, 15),\n",
    "    'knn__weights': ['uniform', 'distance']\n",
    "}]\n",
    "\n",
    "# Configurar la validación cruzada estratificada\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "# Usando precisión como métrica de scoring\n",
    "grid_search_k = GridSearchCV(pipeline, param_grid, cv=k_fold, scoring='precision', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search_k.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Obtener los mejores parámetros y la mejor puntuación\n",
    "best_parameters = grid_search_k.best_params_\n",
    "best_score = grid_search_k.best_score_\n",
    "\n",
    "# Predicciones en el conjunto de test\n",
    "model_pred_knn = grid_search_k.predict(X_test)\n",
    "\n",
    "# Calcular la precisión en el conjunto de test\n",
    "precision_test = precision_score(y_test, model_pred_knn)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejores parámetros: \", best_parameters)\n",
    "print(\"Mejor score de entrenamiento: \", best_score)\n",
    "print('Precisión en el conjunto de test: ', precision_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regresión logistica L1/L2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score en el conjunto de entrenamiento: 0.5281\n",
      "Score en el conjunto de prueba: 0.2848\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN()\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_trainval, y_trainval)\n",
    "\n",
    "# Crear el pipeline solo con la estandarización y el modelo\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # Estandarizar los datos\n",
    "    ('model', LogisticRegression(penalty='l1', solver='liblinear'))  # Regresión Logística con L1\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline a los datos sobremuestreados\n",
    "pipeline.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_predadl1 = pipeline.predict(X_test)\n",
    "\n",
    "# Obtener los scores (precisión) en los conjuntos de entrenamiento y prueba\n",
    "train_score = pipeline.score(X_resampled, y_resampled)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "# Imprimir los scores\n",
    "print(f'Score en el conjunto de entrenamiento: {train_score:.4f}')\n",
    "print(f'Score en el conjunto de prueba: {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.2578\n",
      "Recall: 0.9443\n",
      "F1-score: 0.4050\n",
      "AUC: 0.5020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_probl1 = pipeline.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "\n",
    "# Calcular las métricas\n",
    "precision = precision_score(y_test, y_predadl1)\n",
    "recall = recall_score(y_test, y_predadl1)\n",
    "f1 = f1_score(y_test, y_predadl1)\n",
    "auc = roc_auc_score(y_test, y_probl1)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(f'Precisión: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'AUC: {auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score en el conjunto de entrenamiento: 0.5281\n",
      "Score en el conjunto de prueba: 0.2847\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN()\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_trainval, y_trainval)\n",
    "\n",
    "# Crear el pipeline solo con la estandarización y el modelo\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),           # Estandarizar los datos\n",
    "    ('model', LogisticRegression(penalty='l2', solver='liblinear'))  # Regresión Logística con L1\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline a los datos sobremuestreados\n",
    "pipeline.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_predl2 = pipeline.predict(X_test)\n",
    "\n",
    "# Obtener los scores (precisión) en los conjuntos de entrenamiento y prueba\n",
    "train_score = pipeline.score(X_resampled, y_resampled)\n",
    "test_score = pipeline.score(X_test, y_test)\n",
    "\n",
    "# Imprimir los scores\n",
    "print(f'Score en el conjunto de entrenamiento: {train_score:.4f}')\n",
    "print(f'Score en el conjunto de prueba: {test_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.2579\n",
      "Recall: 0.9454\n",
      "F1-score: 0.4053\n",
      "AUC: 0.5003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_probl2 = pipeline.predict_proba(X_test)[:, 1]  # Probabilidades para la clase positiva\n",
    "\n",
    "# Calcular las métricas\n",
    "precision = precision_score(y_test, y_predl2)\n",
    "recall = recall_score(y_test, y_predl2)\n",
    "f1 = f1_score(y_test, y_predl2)\n",
    "auc = roc_auc_score(y_test, y_predl2)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(f'Precisión: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')\n",
    "print(f'AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clasificador Bayesiano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4571\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_trainval)\n",
    "\n",
    "# Aplicar ADASYN para balancear las clases en el conjunto de entrenamiento\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train_sc, y_trainval)\n",
    "\n",
    "# Entrenamiento del clasificador BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Transformación de los datos de test\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "# Predicción en el conjunto de test\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5643\n",
      "Test Accuracy: 0.4571\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = clf.score(X_train_res, y_train_res)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "y_pred = clf.predict(X_test_sc)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores:\n",
      "  Accuracy: 0.4571\n",
      "  Precision: 0.2589\n",
      "  Recall: 0.5938\n",
      "  F1 Score: 0.3606\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train_res)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "y_test_pred = clf.predict(X_test_sc)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "print(f\"Test Scores:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  Precision: {test_precision:.4f}\")\n",
    "print(f\"  Recall: {test_recall:.4f}\")\n",
    "print(f\"  F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tablas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **sin addasyn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Precisión</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clasificación Bayesiana</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-NN sin ADASIN</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.4995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L1/L2 Penalty Logistic Regression</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Modelo  Precisión  Recall  F1-Score     AUC\n",
       "0            Clasificación Bayesiana     0.0000  0.0000    0.0000  0.5010\n",
       "1                    K-NN sin ADASIN     0.2434  0.0421    0.0717  0.4995\n",
       "2  L1/L2 Penalty Logistic Regression     0.0000  0.0000    0.0000  0.4984"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Modelo': ['Clasificación Bayesiana', 'K-NN sin ADASIN', 'L1/L2 Penalty Logistic Regression'],\n",
    "    'Precisión': [0.0000, 0.2434, 0.0000],\n",
    "    'Recall': [0.0000, 0.0421, 0.0000],\n",
    "    'F1-Score': [0.0000, 0.0717, 0.0000],\n",
    "    'AUC': [0.5010, 0.4995, 0.4984]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Mostrar la tabla\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Con addasyn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Precisión</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clasificación Bayesiana</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>0.3606</td>\n",
       "      <td>0.4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-NN con ADASIN</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.4995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression L1</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.5020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression L2</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.5003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Modelo  Precisión  Recall  F1-Score     AUC\n",
       "0  Clasificación Bayesiana     0.2589  0.5938    0.3606  0.4571\n",
       "1          K-NN con ADASIN     0.2434  0.0421    0.0717  0.4995\n",
       "2   Logistic Regression L1     0.2578  0.9443    0.4050  0.5020\n",
       "3   Logistic Regression L2     0.2579  0.9454    0.4053  0.5003"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_adasin = {\n",
    "    'Modelo': ['Clasificación Bayesiana', 'K-NN con ADASIN', 'Logistic Regression L1', 'Logistic Regression L2'],\n",
    "    'Precisión': [0.2589, 0.2434, 0.2578, 0.2579],\n",
    "    'Recall': [0.5938, 0.0421, 0.9443, 0.9454],\n",
    "    'F1-Score': [0.3606, 0.0717, 0.4050, 0.4053],\n",
    "    'AUC': [0.4571, 0.4995, 0.5020, 0.5003]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_adasin = pd.DataFrame(data_adasin)\n",
    "\n",
    "# Mostrar la tabla\n",
    "df_adasin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusiones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que los modelos obtuvieron un mejor desempeño al aplicar el balanceo de clases utilizando ADASYN. Además, los tiempos de ejecución se redujeron, ya que las clases tenían inicialmente más observaciones en la clase 0 que en la clase 1. Los modelos sin ADASYN, como el clasificador bayesiano y la regresión logística, no lograron un rendimiento óptimo debido al problema de desbalanceo de clases. Sin embargo, al aplicar ADASYN, se observó una mejora significativa en los scores, mostrando que la técnica de balanceo fue efectiva en corregir este problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
